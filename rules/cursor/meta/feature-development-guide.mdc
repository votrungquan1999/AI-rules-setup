---
alwaysApply: true
description: 'Cursor feature development workflow: step-by-step guide with planning, incremental implementation, test-driven approach, and progress tracking'
---

# Feature Development Guide

This document outlines the recommended approach for implementing features and tasks in this codebase.

## Core Principles

1. **Understand Context First** - Read as many relevant files as possible to understand the codebase before planning
2. **Plan High-Level** - Define steps and acceptance criteria, not implementation details
3. **Test During Implementation** - Define test scenarios when implementing each step, not during planning
4. **Track Progress** - Write progress to a file for context switching and interruptions
5. **Incremental Progress** - Complete one step fully before moving to the next
6. **Test Each Step** - Prove each step works before building on top of it
7. **One Test at a Time** - Write exactly one test, see it fail, make it pass, then move to the next test. This ensures incremental validation and prevents skipping test coverage.

---

## Phase 1: Planning

**Goal:** Break down work into implementable steps with clear acceptance criteria.

**Step 1: Understand the Context**

Before creating your plan, read as many relevant files as possible to understand:

- Existing patterns and conventions in the codebase
- Related features or components that might be affected
- Architecture and structure of the area you'll be modifying
- Testing patterns and utilities already in place
- Types, interfaces, and data models

This context-gathering phase helps you create a more accurate plan and avoid surprises during implementation.

**Important:** If anything is unclear or ambiguous, ask the user clarifying questions. Do not assume implementation details, architectural decisions, or requirements. It's better to ask questions upfront than to make incorrect assumptions that lead to rework later.

**Step 2: Create the Plan**

Create plan based on the gathered information. MUST pause for user review and wait for user to say "implement it" before starting implementation phase.

**What to include:**

- List of implementation steps in logical order
- Acceptance criteria for each step (what "done" looks like)
- Test type for each step (unit, integration, e2e, etc.) - ONLY the test type, not test cases yet
- Dependencies between steps
- Any known blockers or risks

**What NOT to include:**

- Specific test scenarios or test code
- Detailed implementation approaches
- Exact function signatures or component structure
- Database schema details

**Example Plan:**

```markdown
## Task: [Task name]

### Step 1: [High-level description]

**AC:** [What must be true when this step is done]

**Test Type:** unit

### Step 2: [High-level description]

**AC:** [What must be true when this step is done]

**Test Type:** integration
```

**Create Progress File:**
Create a file (e.g., `IMPLEMENTATION_PROGRESS.md`) to track completed steps. Add steps ONLY as you work on them, not in advance.

```markdown
# Implementation Progress: [Task Name]

### Step 1: [Description]

**Status:** ‚úÖ Done

**E2E Tests Written (2 tests, all passing ‚úÖ):**

1. ‚úÖ Popover open/close behavior
2. ‚úÖ Form inputs render correctly

**Notes:** Created form components, added client-side validation
```

---

## Phase 2: Implement Each Step

**For each step in your plan:**

1. **Add step to progress file** - When starting a new step, add it with üîÑ In Progress status
2. **Define test scenarios** - NOW figure out what tests are needed for THIS step (you can define empty test scenarios first)

**Then, for EACH test scenario, follow this iterative process:**

3. **Write ONE test** - Write exactly 1 test at a time (you can start with an empty test that just has a description)
4. **Run the test** - Run the test to verify it fails (this confirms the test is actually testing something)
5. **Implement code** - Write the minimum code needed to make this ONE test pass
6. **Run the test again** - Verify the test now passes
7. **Repeat** - If more test scenarios remain, go back to step 3 for the next test. Continue until all test scenarios are written and passing.

**After all tests are passing:**

8. **Run linting** - Check for code quality issues and fix any problems
9. **Verify** - All tests pass, acceptance criteria met
10. **Mark step as complete** - Update progress file with ‚úÖ Done, test list, and notes
11. **Move to next step** - Only after current step is complete

### When Writing Tests

**IMPORTANT:** Before writing any tests, locate the "4 Pillars of Testing" document in the project (usually in `.cursor/rules/`, `docs/`, or `repo_knowledge/`). Use it to guide your test writing.

**If you cannot find the 4 Pillars document:** STOP and ask the user where it is located.

Follow the guidelines in the 4 Pillars document when defining test scenarios and writing tests.

**Key TDD Principle:** Always write ONE test at a time, see it fail, make it pass, then move to the next test. This ensures you're building incrementally and each test is actually validating behavior.

---

## Progress Tracking Format

```markdown
# Implementation Progress: [Task Name]

### Step 1: [Description]

**Status:** ‚úÖ Done

**Tests Written (2 tests, all passing ‚úÖ):**

1. ‚úÖ Test description
2. ‚úÖ Test description

**Notes:** Brief summary of what was accomplished

### Step 2: [Description]

**Status:** üîÑ In Progress

**Tests Written (1 of 3 tests passing ‚úÖ):**

1. ‚úÖ Test passing
2. ‚è≥ Test not written yet
3. ‚è≥ Test failing

**Notes:** Current work in progress
```

**Status indicators:**

- ‚úÖ Done - Step complete, tests passing, AC met
- üîÑ In Progress - Currently working on this step

**Test indicators:**

- ‚úÖ Test passing
- ‚è≥ Test not written yet or failing

**Update frequency:**

- Add step to progress file when you start working on it (üîÑ In Progress)
- Update tests list as you write them (‚è≥ ‚Üí ‚úÖ)
- Mark step complete when done (üîÑ In Progress ‚Üí ‚úÖ Done)
- Add notes about what was accomplished or issues encountered

**Important:** Don't pre-create steps in the progress file. The plan file already has all steps defined. Only add a step to progress when you actually start working on it.

### What to Avoid During Implementation

- ‚ùå Skipping tests for any step
- ‚ùå Moving to next step with failing tests
- ‚ùå Not updating progress file
- ‚ùå Writing tests without consulting project testing guidelines
- ‚ùå Pre-creating steps in progress file (only add when working on them)
